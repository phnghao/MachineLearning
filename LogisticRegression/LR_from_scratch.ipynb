{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e705a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41865620",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, lr = 0.1, eps = 1e-6, num_iter = 1000, verbose = False):\n",
    "        self.lr = lr\n",
    "        self.eps = eps\n",
    "        self.num_iter = num_iter\n",
    "        self.verbose = verbose\n",
    "        self.loss_dis = []\n",
    "\n",
    "    def add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0],1))\n",
    "        return np.concatenate((intercept, X))\n",
    "    \n",
    "    @staticmethod\n",
    "    def stable_sigmoid(x):\n",
    "       z = np.zeros_like(x)\n",
    "       z[x >= 0] = 1/(1 + np.exp(-x))\n",
    "       z[x < 0] = np.exp(x[x < 0]) \n",
    "       z[x < 0] = z[x < 0] / (1 + z[ x < 0])\n",
    "       return z\n",
    "    \n",
    "    def loss(self, m, y, y_hat):\n",
    "        return -(1/m)*(y.T @ np.log(y_hat + self.eps) + (1-y).T @ np.log(1-y_hat + self.eps))\n",
    "    \n",
    "    def grad_desc(self, X, y):\n",
    "        m = len(y)\n",
    "        y_hat = self.stable_sigmoid( np.dot(X, self.theta))\n",
    "        grad = (1/m)* X.T @ (y_hat.T - y.T)\n",
    "        new_theta = self.theta - self.lr*grad\n",
    "        return new_theta\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        samples, features = X.shape[:2]\n",
    "\n",
    "        X = self.add_intercept(X)\n",
    "\n",
    "        self.theta = np.zeros(features+1)\n",
    "\n",
    "        pbar = tqdm(range(self.num_iter))\n",
    "\n",
    "        for epoch in pbar:\n",
    "\n",
    "            y_hat = self.stable_sigmoid( X @ self.theta)\n",
    "\n",
    "            new_theta = self.grad_desc(X,y) \n",
    "\n",
    "            if np.linalg.norm(new_theta - self.theta, 1) < self.eps:\n",
    "                self.theta = new_theta\n",
    "                break\n",
    "\n",
    "            self.theta = new_theta\n",
    "\n",
    "            if self.verbose is True:\n",
    "                loss = self.loss(samples, y, y_hat)\n",
    "                self.loss_dis.append(loss)\n",
    "                pbar.set_description(f'epoch {epoch}: loss = {loss:.2f}')   \n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.stable_sigmoid( X @ self.theta)\n",
    "        return (y_pred >= 0.5).astype(int)\n",
    "\n",
    "    def display_loss(self):\n",
    "        plt.figure(figsize = (10,7))\n",
    "        plt.plot(self.loss_dis)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        accuracy = np.mean(y_pred == y)\n",
    "        print(f'Accuracy: {accuracy:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4c31c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
